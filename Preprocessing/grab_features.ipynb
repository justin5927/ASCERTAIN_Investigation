{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_path = '../ASCERTAIN_Features/Dt_ECGFeatures.mat'\n",
    "mat = scipy.io.loadmat(ecg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'ECGFailures_58', 'ECGFeatures_58']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[4]\n",
    "participants_num = len(mat[key][0])\n",
    "recording_num = len(mat[key][0][0])\n",
    "features_num = len(mat[key][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_feature_names = [\n",
    "    \"low_freq_psd_1\", \"low_freq_psd_2\", \"low_freq_psd_3\", \"low_freq_psd_4\", \"low_freq_psd_5\",\n",
    "    \"low_freq_psd_6\", \"low_freq_psd_7\", \"low_freq_psd_8\", \"low_freq_psd_9\",\"low_freq_psd_10\",\n",
    "    \"slow_response_pds_1\", \"slow_response_pds_2\", \"slow_response_pds_3\", \"slow_response_pds_4\",\n",
    "    \"ibi_1\", \"ibi_2\", \"ibi_3\", \"ibi_4\", \"ibi_5\", \"ibi_6\",\n",
    "    \"hr_1\", \"hr_2\", \"hr_3\", \"hr_4\", \"hr_5\", \"hr_6\",\n",
    "    \"hrv_1\", \"hrv_2\", \"hrv_3\", \"hrv_4\", \"hrv_5\", \"hrv_6\"\n",
    "]\n",
    "ecg_dict = {key: [] for key in ecg_feature_names} \n",
    "ecg_participants_data = [ecg_dict for _ in range(participants_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(participants_num):\n",
    "    for r in range(recording_num):\n",
    "        for f in range(features_num):\n",
    "            ecg_participants_data[p][ecg_feature_names[f]].append(mat[key][0][p][r][f])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Report Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports_path = '../ASCERTAIN_Features/Dt_SelfReports.mat'\n",
    "mat = scipy.io.loadmat(self_reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'ClipNumbers', 'Length', 'Ratings']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[5]\n",
    "emotions_num = len(mat[key])\n",
    "participants_num = len(mat[key][0])\n",
    "recording_num = len(mat[key][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"Arousal\", \"Valence\", \"Engagement\", \"Liking\", \"Familiarity\"]\n",
    "emo_dict = {emo: [] for emo in emotions}\n",
    "self_reports_participants_data = [emo_dict for _ in range(participants_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for e in range(emotions_num):\n",
    "    for p in range(participants_num):\n",
    "        for r in range(recording_num):\n",
    "            self_reports_participants_data[p][emotions[e]].append(mat[key][e][p][r])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_path = '../ASCERTAIN_Features/Dt_Personality.mat'\n",
    "mat = scipy.io.loadmat(personality_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'Personality']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[3]\n",
    "participants_num = len(mat[key])\n",
    "personalities_num = len(mat[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = [\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \"Emotional Stability\",\"Openness\"]\n",
    "traits_dict = {trait: [] for trait in traits}\n",
    "personality_participants_data = [traits_dict for _ in range(participants_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in range(participants_num):\n",
    "    for per in range(personalities_num):\n",
    "            personality_participants_data[par][traits[per]].append(mat[key][par][per])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG \n",
    "ecg_df = pd.DataFrame(ecg_participants_data)\n",
    "ecg_df['participants'] = ecg_df.index\n",
    "ecg_df = ecg_df.apply(lambda col: col.explode()).assign(users=lambda df: df.index)[['participants'] + ecg_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self reports \n",
    "self_reports_df = pd.DataFrame(self_reports_participants_data)\n",
    "self_reports_df = self_reports_df.apply(lambda col: col.explode())\n",
    "self_reports_df['participants'] = self_reports_df.index\n",
    "self_reports_df = self_reports_df[['participants'] + emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personalities \n",
    "personalities_df = pd.DataFrame(personality_participants_data)\n",
    "personalities_df = personalities_df.apply(lambda col: col.explode())\n",
    "personalities_df['participants'] = personalities_df.index\n",
    "personalities_df = personalities_df[['participants'] + traits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine self reports and ecg features\n",
    "self_reports_df = self_reports_df.drop(columns=['participants'])\n",
    "features_df = pd.concat([ecg_df, self_reports_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folder \n",
    "data_path = \"../data\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "# Create csvs\n",
    "features_df.to_csv(os.path.join(data_path, \"features.csv\"), index=False)\n",
    "personalities_df.to_csv(os.path.join(data_path, \"personalities.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features \n",
    "# Only keep columns which have any non-zero value and any non-NaN value.\n",
    "preprocessed_features_df = features_df.loc[:, (features_df != 0).any(axis=0) & features_df.notna().any(axis=0)]\n",
    "# Calculate a threshold which is half the number of columns \n",
    "threshold = len(preprocessed_features_df.columns) // 2 \n",
    "# Remove the rows where the number of NaN values is greater than or equal to the threshold\n",
    "preprocessed_features_df = preprocessed_features_df.dropna(thresh=threshold)\n",
    "# Keep only those columns which have any non-zero value and any non-NaN value - Reprocess so values after rows were removed\n",
    "preprocessed_features_df = preprocessed_features_df.loc[:, (preprocessed_features_df != 0).any(axis=0) & preprocessed_features_df.notna().any(axis=0)]\n",
    "# Drop any rows that have any NaN values - This is strict but could be removed later on\n",
    "preprocessed_features_df = preprocessed_features_df.dropna()\n",
    "scaler = MinMaxScaler()\n",
    "# Apply the MinMaxScaler to the dataframe to normalize all feature values between 0 and 1.\n",
    "preprocessed_features_df = pd.DataFrame(scaler.fit_transform(preprocessed_features_df), columns=preprocessed_features_df.columns)\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "preprocessed_features_df.to_csv(os.path.join(data_path, \"preprocessed_features.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all of the NaN and 0 columns and also any rows that contain NaNs then scales all values from 0 to 1\n",
    "\n",
    "This removes all psd features and some ibi features. \n",
    "\n",
    "\n",
    "Could clean this up by removing all rows with NaNs then removing columns with all 0s. This method above allows use to pull out differnt parts of the process. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
