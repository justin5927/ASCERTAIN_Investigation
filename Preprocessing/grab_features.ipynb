{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_path = '../ASCERTAIN_Features/Dt_ECGFeatures.mat'\n",
    "mat = scipy.io.loadmat(ecg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'ECGFailures_58', 'ECGFeatures_58']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[4]\n",
    "participants_num = len(mat[key][0])\n",
    "recording_num = len(mat[key][0][0])\n",
    "features_num = len(mat[key][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_feature_names = [\n",
    "    \"low_freq_psd_1\", \"low_freq_psd_2\", \"low_freq_psd_3\", \"low_freq_psd_4\", \"low_freq_psd_5\",\n",
    "    \"low_freq_psd_6\", \"low_freq_psd_7\", \"low_freq_psd_8\", \"low_freq_psd_9\",\"low_freq_psd_10\",\n",
    "    \"slow_response_pds_1\", \"slow_response_pds_2\", \"slow_response_pds_3\", \"slow_response_pds_4\",\n",
    "    \"ibi_1\", \"ibi_2\", \"ibi_3\", \"ibi_4\", \"ibi_5\", \"ibi_6\",\n",
    "    \"hr_1\", \"hr_2\", \"hr_3\", \"hr_4\", \"hr_5\", \"hr_6\",\n",
    "    \"hrv_1\", \"hrv_2\", \"hrv_3\", \"hrv_4\", \"hrv_5\", \"hrv_6\"\n",
    "]\n",
    "ecg_dict = {key: [] for key in ecg_feature_names} \n",
    "ecg_participants_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(participants_num):\n",
    "    for r in range(recording_num):\n",
    "        values = []\n",
    "        for f in range(features_num):\n",
    "            values.append(mat[key][0][p][r][f])\n",
    "        ecg_participants_data.append([p, r] + values)\n",
    "\n",
    "column_names = [\"participants\", \"recordings\"] + ecg_feature_names \n",
    "ecg_df = pd.DataFrame(ecg_participants_data, columns=column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Report Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports_path = '../ASCERTAIN_Features/Dt_SelfReports.mat'\n",
    "mat = scipy.io.loadmat(self_reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'ClipNumbers', 'Length', 'Ratings']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[5]\n",
    "emotions_num = len(mat[key])\n",
    "participants_num = len(mat[key][0])\n",
    "recording_num = len(mat[key][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 58, 36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"Arousal\", \"Valence\", \"Engagement\", \"Liking\", \"Familiarity\"]\n",
    "emo_dict = {emo: [] for emo in emotions}\n",
    "self_reports_participants_data = [emo_dict for _ in range(participants_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_report_data = []\n",
    "for p in range(participants_num):\n",
    "    for r in range(recording_num):\n",
    "        values = []\n",
    "        for e in range(emotions_num):\n",
    "            values.append(mat[key][e][p][r])\n",
    "        self_report_data.append([p, r] + values)\n",
    "\n",
    "column_names = [\"participants\", \"recordings\"] + emotions \n",
    "self_reports_df = pd.DataFrame(self_report_data, columns=column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_path = '../ASCERTAIN_Features/Dt_Personality.mat'\n",
    "mat = scipy.io.loadmat(personality_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'Personality']\n"
     ]
    }
   ],
   "source": [
    "key_names = list(mat.keys())\n",
    "print(key_names)\n",
    "key = list(key_names)[3]\n",
    "participants_num = len(mat[key])\n",
    "personalities_num = len(mat[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits = [\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \"Emotional Stability\",\"Openness\"]\n",
    "traits_dict = {trait: [] for trait in traits}\n",
    "personality_participants_data = [traits_dict for _ in range(participants_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in range(participants_num):\n",
    "    for per in range(personalities_num):\n",
    "            personality_participants_data[par][traits[per]].append(mat[key][par][per])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_data = []\n",
    "for p in range(participants_num):\n",
    "    for r in range(recording_num):\n",
    "        values = []\n",
    "        for per in range(personalities_num):\n",
    "            values.append(mat[key][p][per])\n",
    "        personality_data.append([p, r] + values)\n",
    "\n",
    "column_names = [\"participants\", \"recordings\"] + traits \n",
    "personalities_df = pd.DataFrame(personality_data, columns=column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants</th>\n",
       "      <th>recordings</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Emotional Stability</th>\n",
       "      <th>Openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "      <td>2088.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.306897</td>\n",
       "      <td>5.091379</td>\n",
       "      <td>5.144828</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.953448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.744679</td>\n",
       "      <td>10.390783</td>\n",
       "      <td>1.069233</td>\n",
       "      <td>0.758875</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.909903</td>\n",
       "      <td>0.642406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       participants   recordings  Extraversion  Agreeableness  \\\n",
       "count   2088.000000  2088.000000   2088.000000    2088.000000   \n",
       "mean      28.500000    17.500000      4.306897       5.091379   \n",
       "std       16.744679    10.390783      1.069233       0.758875   \n",
       "min        0.000000     0.000000      2.600000       3.200000   \n",
       "25%       14.000000     8.750000      3.200000       4.500000   \n",
       "50%       28.500000    17.500000      4.450000       5.100000   \n",
       "75%       43.000000    26.250000      5.200000       5.600000   \n",
       "max       57.000000    35.000000      6.200000       6.700000   \n",
       "\n",
       "       Conscientiousness  Emotional Stability     Openness  \n",
       "count        2088.000000          2088.000000  2088.000000  \n",
       "mean            5.144828             4.137931     4.953448  \n",
       "std             0.768562             0.909903     0.642406  \n",
       "min             3.400000             2.000000     3.700000  \n",
       "25%             4.600000             3.500000     4.600000  \n",
       "50%             5.200000             4.200000     4.900000  \n",
       "75%             5.700000             4.900000     5.300000  \n",
       "max             6.900000             5.700000     6.600000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Personality so we can bin them \n",
    "personalities_df = personalities_df.astype(float)\n",
    "personalities_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Personality Features into Negative, Neutral, Positive\n",
    "bins = [0, 3, 5, 7] \n",
    "bin_labels = ['Negative', 'Neutral', 'Positive']\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# Apply the binning to all columns\n",
    "for col in personalities_df.columns:\n",
    "    personalities_df[f'{col}_bin'] = pd.cut(personalities_df[col], bins=bins, labels=labels)\n",
    "personalities_df = personalities_df.drop(columns=[\"participants_bin\", \"recordings_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine self reports and ecg features\n",
    "self_reports_df = self_reports_df.drop(columns=[\"participants\", \"recordings\"])\n",
    "personalities_df = personalities_df.drop(columns=[\"participants\", \"recordings\"])\n",
    "all_data_df = pd.concat([ecg_df, self_reports_df, personalities_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folder \n",
    "data_path = \"../data\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "# Create csvs\n",
    "all_data_df.to_csv(os.path.join(data_path, \"org_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Extraversion', 'Agreeableness', 'Conscientiousness',\n",
       "       'Emotional Stability', 'Openness', 'Extraversion_bin',\n",
       "       'Agreeableness_bin', 'Conscientiousness_bin', 'Emotional Stability_bin',\n",
       "       'Openness_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalities_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features \n",
    "# Only keep columns which have any non-zero value and any non-NaN value.\n",
    "preprocessed_features_df = all_data_df.loc[:, (all_data_df != 0).any(axis=0) & all_data_df.notna().any(axis=0)]\n",
    "# Calculate a threshold which is half the number of columns \n",
    "threshold = len(preprocessed_features_df.columns) // 2 \n",
    "# Remove the rows where the number of NaN values is greater than or equal to the threshold\n",
    "preprocessed_features_df = preprocessed_features_df.dropna(thresh=threshold)\n",
    "# Keep only those columns which have any non-zero value and any non-NaN value - Reprocess so values after rows were removed\n",
    "preprocessed_features_df = preprocessed_features_df.loc[:, (preprocessed_features_df != 0).any(axis=0) & preprocessed_features_df.notna().any(axis=0)]\n",
    "# Drop any rows that have any NaN values - This is strict but could be removed later on\n",
    "preprocessed_features_df = preprocessed_features_df.dropna()\n",
    "# Apply the MinMaxScaler to the dataframe to normalize all feature values between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "non_scaled_features = ['participants', 'recordings', 'Extraversion', 'Agreeableness',\n",
    "       'Conscientiousness', 'Emotional Stability', 'Openness',\n",
    "       'Extraversion_bin', 'Agreeableness_bin', 'Conscientiousness_bin',\n",
    "       'Emotional Stability_bin', 'Openness_bin']\n",
    "scaled_features_df = preprocessed_features_df.drop(columns=non_scaled_features)\n",
    "scaled_features_df = pd.DataFrame(scaler.fit_transform(scaled_features_df), columns=scaled_features_df.columns)\n",
    "for f in non_scaled_features:\n",
    "    scaled_features_df[f] = preprocessed_features_df[f]\n",
    "# Save to csv\n",
    "scaled_features_df.to_csv(os.path.join(data_path, \"preprocessed_data.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all of the NaN and 0 columns and also any rows that contain NaNs then scales all values from 0 to 1\n",
    "\n",
    "This removes all psd features and some ibi features. \n",
    "\n",
    "\n",
    "Could clean this up by removing all rows with NaNs then removing columns with all 0s. This method above allows use to pull out differnt parts of the process. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
