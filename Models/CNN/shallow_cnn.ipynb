{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = \"../../data\"\n",
    "X_train = pd.read_csv(os.path.join(data_path, \"X_train_pca.csv\")).values\n",
    "y_train_org = pd.read_csv(os.path.join(data_path, \"y_train_pca.csv\"))\n",
    "X_test = pd.read_csv(os.path.join(data_path, \"X_test_pca.csv\")).values\n",
    "y_test_org = pd.read_csv(os.path.join(data_path, \"y_test_pca.csv\"))\n",
    "traits = ['Extraversion', 'Agreeableness', 'Conscientiousness', 'Emotional Stability', 'Openness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_path = \"../../results\"\n",
    "specific_results_path = os.path.join(\"../../results\", \"cnn_classification\")\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(specific_results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_auc(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    n_classes = np.unique(y_true)\n",
    "    roc_auc_scores = []\n",
    "    for label in n_classes:\n",
    "        # Create binary labels for the current class vs. all other classes\n",
    "        y_true_class = (y_true == label).astype(int)\n",
    "        y_pred_class = (y_pred == label).astype(int)\n",
    "        \n",
    "        # Calculate ROC AUC for the current class\n",
    "        roc_auc = roc_auc_score(y_true_class, y_pred_class)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    return roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Extraversion\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10058 (39.29 KB)\n",
      "Trainable params: 10058 (39.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 2.0961 - accuracy: 0.3918 - val_loss: 1.7507 - val_accuracy: 0.5241\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.4524 - accuracy: 0.4976 - val_loss: 1.1517 - val_accuracy: 0.5241\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0928 - accuracy: 0.4970 - val_loss: 1.0277 - val_accuracy: 0.5027\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0262 - accuracy: 0.5059 - val_loss: 0.9927 - val_accuracy: 0.5401\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0211 - accuracy: 0.5036 - val_loss: 0.9804 - val_accuracy: 0.5294\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0062 - accuracy: 0.5143 - val_loss: 0.9764 - val_accuracy: 0.5401\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 1.0031 - accuracy: 0.5042 - val_loss: 0.9683 - val_accuracy: 0.5508\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9981 - accuracy: 0.5065 - val_loss: 0.9630 - val_accuracy: 0.5561\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.5131 - val_loss: 0.9643 - val_accuracy: 0.5401\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.5178 - val_loss: 0.9589 - val_accuracy: 0.5668\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9838 - accuracy: 0.5155 - val_loss: 0.9615 - val_accuracy: 0.5241\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9846 - accuracy: 0.5202 - val_loss: 0.9521 - val_accuracy: 0.5401\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9810 - accuracy: 0.5273 - val_loss: 0.9564 - val_accuracy: 0.5080\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9797 - accuracy: 0.5232 - val_loss: 0.9479 - val_accuracy: 0.5348\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9789 - accuracy: 0.5202 - val_loss: 0.9518 - val_accuracy: 0.5241\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9469 - val_accuracy: 0.5508\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9751 - accuracy: 0.5256 - val_loss: 0.9414 - val_accuracy: 0.5561\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9651 - accuracy: 0.5202 - val_loss: 0.9429 - val_accuracy: 0.5401\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9665 - accuracy: 0.5297 - val_loss: 0.9415 - val_accuracy: 0.5080\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9696 - accuracy: 0.5309 - val_loss: 0.9371 - val_accuracy: 0.5455\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9622 - accuracy: 0.5398 - val_loss: 0.9380 - val_accuracy: 0.5455\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.5351 - val_loss: 0.9308 - val_accuracy: 0.5615\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9731 - accuracy: 0.5256 - val_loss: 0.9357 - val_accuracy: 0.5294\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9671 - accuracy: 0.5339 - val_loss: 0.9349 - val_accuracy: 0.5401\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9552 - accuracy: 0.5386 - val_loss: 0.9319 - val_accuracy: 0.5401\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9592 - accuracy: 0.5315 - val_loss: 0.9284 - val_accuracy: 0.5615\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9542 - accuracy: 0.5410 - val_loss: 0.9228 - val_accuracy: 0.5615\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9574 - accuracy: 0.5238 - val_loss: 0.9271 - val_accuracy: 0.5401\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.5535 - val_loss: 0.9229 - val_accuracy: 0.5615\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5541 - val_loss: 0.9237 - val_accuracy: 0.5455\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.5369 - val_loss: 0.9231 - val_accuracy: 0.5561\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9416 - accuracy: 0.5470 - val_loss: 0.9246 - val_accuracy: 0.5134\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9451 - accuracy: 0.5488 - val_loss: 0.9171 - val_accuracy: 0.5508\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9433 - accuracy: 0.5517 - val_loss: 0.9226 - val_accuracy: 0.5348\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9442 - accuracy: 0.5476 - val_loss: 0.9223 - val_accuracy: 0.5134\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9374 - accuracy: 0.5505 - val_loss: 0.9121 - val_accuracy: 0.5455\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9353 - accuracy: 0.5535 - val_loss: 0.9191 - val_accuracy: 0.5508\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.5654 - val_loss: 0.9191 - val_accuracy: 0.5561\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9317 - accuracy: 0.5511 - val_loss: 0.9140 - val_accuracy: 0.5401\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9266 - accuracy: 0.5547 - val_loss: 0.9153 - val_accuracy: 0.5775\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9304 - accuracy: 0.5577 - val_loss: 0.9167 - val_accuracy: 0.5348\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.5618 - val_loss: 0.9154 - val_accuracy: 0.5455\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9238 - accuracy: 0.5666 - val_loss: 0.9101 - val_accuracy: 0.5508\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5565 - val_loss: 0.9104 - val_accuracy: 0.5668\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9193 - accuracy: 0.5690 - val_loss: 0.9102 - val_accuracy: 0.5401\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.5678 - val_loss: 0.9114 - val_accuracy: 0.5668\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9268 - accuracy: 0.5547 - val_loss: 0.9154 - val_accuracy: 0.5561\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9186 - accuracy: 0.5612 - val_loss: 0.9035 - val_accuracy: 0.5561\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.5702 - val_loss: 0.9015 - val_accuracy: 0.5829\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.5731 - val_loss: 0.9008 - val_accuracy: 0.5615\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 0.5684 - val_loss: 0.9030 - val_accuracy: 0.5508\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9135 - accuracy: 0.5618 - val_loss: 0.9020 - val_accuracy: 0.5722\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9137 - accuracy: 0.5612 - val_loss: 0.9021 - val_accuracy: 0.5455\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.5678 - val_loss: 0.8999 - val_accuracy: 0.5615\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9045 - accuracy: 0.5773 - val_loss: 0.8999 - val_accuracy: 0.5561\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.5874 - val_loss: 0.8961 - val_accuracy: 0.5668\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9031 - accuracy: 0.5749 - val_loss: 0.9019 - val_accuracy: 0.5668\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9035 - accuracy: 0.5719 - val_loss: 0.9012 - val_accuracy: 0.5561\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.5719 - val_loss: 0.9019 - val_accuracy: 0.5668\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.5749 - val_loss: 0.9012 - val_accuracy: 0.5615\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8980 - accuracy: 0.5797 - val_loss: 0.9000 - val_accuracy: 0.5668\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8951 - accuracy: 0.5713 - val_loss: 0.8938 - val_accuracy: 0.5615\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5761 - val_loss: 0.8970 - val_accuracy: 0.5722\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5838 - val_loss: 0.8915 - val_accuracy: 0.5775\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8851 - accuracy: 0.5951 - val_loss: 0.8899 - val_accuracy: 0.5775\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8825 - accuracy: 0.5916 - val_loss: 0.8876 - val_accuracy: 0.5829\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8912 - accuracy: 0.5862 - val_loss: 0.8924 - val_accuracy: 0.5936\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.5880 - val_loss: 0.8854 - val_accuracy: 0.5936\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.5886 - val_loss: 0.8817 - val_accuracy: 0.5882\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8860 - accuracy: 0.5838 - val_loss: 0.8875 - val_accuracy: 0.5882\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8856 - accuracy: 0.5898 - val_loss: 0.8839 - val_accuracy: 0.5829\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8784 - accuracy: 0.6005 - val_loss: 0.8858 - val_accuracy: 0.5775\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8851 - accuracy: 0.5713 - val_loss: 0.8865 - val_accuracy: 0.5829\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8734 - accuracy: 0.5910 - val_loss: 0.8827 - val_accuracy: 0.5882\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.5892 - val_loss: 0.8808 - val_accuracy: 0.5882\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8768 - accuracy: 0.5969 - val_loss: 0.8768 - val_accuracy: 0.5936\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8789 - accuracy: 0.6029 - val_loss: 0.8801 - val_accuracy: 0.5775\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.5916 - val_loss: 0.8786 - val_accuracy: 0.5775\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6029 - val_loss: 0.8816 - val_accuracy: 0.5882\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8728 - accuracy: 0.5904 - val_loss: 0.8804 - val_accuracy: 0.5775\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8693 - accuracy: 0.5975 - val_loss: 0.8749 - val_accuracy: 0.5882\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.5927 - val_loss: 0.8821 - val_accuracy: 0.5775\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.5809 - val_loss: 0.8811 - val_accuracy: 0.5936\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.5803 - val_loss: 0.8715 - val_accuracy: 0.5936\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.5850 - val_loss: 0.8774 - val_accuracy: 0.5775\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.5963 - val_loss: 0.8752 - val_accuracy: 0.5989\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.5862 - val_loss: 0.8771 - val_accuracy: 0.5936\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8666 - accuracy: 0.6064 - val_loss: 0.8733 - val_accuracy: 0.5829\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.5933 - val_loss: 0.8787 - val_accuracy: 0.5882\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8543 - accuracy: 0.6130 - val_loss: 0.8809 - val_accuracy: 0.5829\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8581 - accuracy: 0.6034 - val_loss: 0.8715 - val_accuracy: 0.5722\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8624 - accuracy: 0.5987 - val_loss: 0.8749 - val_accuracy: 0.5775\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.5886 - val_loss: 0.8755 - val_accuracy: 0.5936\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8599 - accuracy: 0.6070 - val_loss: 0.8671 - val_accuracy: 0.5829\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8623 - accuracy: 0.5981 - val_loss: 0.8746 - val_accuracy: 0.5882\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6070 - val_loss: 0.8730 - val_accuracy: 0.5775\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.6052 - val_loss: 0.8691 - val_accuracy: 0.5882\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8490 - accuracy: 0.6046 - val_loss: 0.8687 - val_accuracy: 0.5936\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8593 - accuracy: 0.6124 - val_loss: 0.8738 - val_accuracy: 0.5829\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8422 - accuracy: 0.5975 - val_loss: 0.8697 - val_accuracy: 0.5882\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.6023 - val_loss: 0.8830 - val_accuracy: 0.5615\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8556 - accuracy: 0.6011 - val_loss: 0.8718 - val_accuracy: 0.5829\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6011 - val_loss: 0.8742 - val_accuracy: 0.5829\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8433 - accuracy: 0.6124 - val_loss: 0.8694 - val_accuracy: 0.5668\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8418 - accuracy: 0.6064 - val_loss: 0.8697 - val_accuracy: 0.5989\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8448 - accuracy: 0.6011 - val_loss: 0.8710 - val_accuracy: 0.5936\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8433 - accuracy: 0.6064 - val_loss: 0.8663 - val_accuracy: 0.5882\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.6118 - val_loss: 0.8712 - val_accuracy: 0.5775\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8424 - accuracy: 0.6011 - val_loss: 0.8727 - val_accuracy: 0.5989\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8349 - accuracy: 0.6106 - val_loss: 0.8695 - val_accuracy: 0.5775\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8368 - accuracy: 0.6100 - val_loss: 0.8670 - val_accuracy: 0.5989\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8405 - accuracy: 0.6076 - val_loss: 0.8658 - val_accuracy: 0.5936\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8494 - accuracy: 0.6106 - val_loss: 0.8653 - val_accuracy: 0.5882\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8390 - accuracy: 0.6058 - val_loss: 0.8707 - val_accuracy: 0.5936\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8273 - accuracy: 0.6260 - val_loss: 0.8733 - val_accuracy: 0.5882\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8334 - accuracy: 0.6183 - val_loss: 0.8673 - val_accuracy: 0.5829\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8392 - accuracy: 0.6118 - val_loss: 0.8803 - val_accuracy: 0.5829\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8283 - accuracy: 0.6266 - val_loss: 0.8725 - val_accuracy: 0.5775\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8308 - accuracy: 0.6165 - val_loss: 0.8687 - val_accuracy: 0.5829\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.6183 - val_loss: 0.8627 - val_accuracy: 0.6096\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.6237 - val_loss: 0.8628 - val_accuracy: 0.5882\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.6201 - val_loss: 0.8575 - val_accuracy: 0.5775\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8294 - accuracy: 0.6124 - val_loss: 0.8636 - val_accuracy: 0.5829\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8390 - accuracy: 0.6118 - val_loss: 0.8618 - val_accuracy: 0.5775\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8265 - accuracy: 0.6219 - val_loss: 0.8667 - val_accuracy: 0.5882\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8178 - accuracy: 0.6344 - val_loss: 0.8627 - val_accuracy: 0.5936\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8257 - accuracy: 0.6213 - val_loss: 0.8680 - val_accuracy: 0.5401\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8183 - accuracy: 0.6243 - val_loss: 0.8606 - val_accuracy: 0.6096\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.6260 - val_loss: 0.8682 - val_accuracy: 0.5829\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8224 - accuracy: 0.6159 - val_loss: 0.8673 - val_accuracy: 0.5829\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8169 - accuracy: 0.6290 - val_loss: 0.8643 - val_accuracy: 0.5882\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8203 - accuracy: 0.6249 - val_loss: 0.8662 - val_accuracy: 0.5936\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8128 - accuracy: 0.6290 - val_loss: 0.8622 - val_accuracy: 0.6043\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.6290 - val_loss: 0.8655 - val_accuracy: 0.5829\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8158 - accuracy: 0.6332 - val_loss: 0.8631 - val_accuracy: 0.5668\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.6266 - val_loss: 0.8645 - val_accuracy: 0.5936\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8142 - accuracy: 0.6195 - val_loss: 0.8636 - val_accuracy: 0.5829\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8027 - accuracy: 0.6332 - val_loss: 0.8553 - val_accuracy: 0.5989\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8175 - accuracy: 0.6308 - val_loss: 0.8715 - val_accuracy: 0.5829\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8225 - accuracy: 0.6183 - val_loss: 0.8533 - val_accuracy: 0.6096\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8112 - accuracy: 0.6290 - val_loss: 0.8505 - val_accuracy: 0.5936\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8090 - accuracy: 0.6356 - val_loss: 0.8620 - val_accuracy: 0.5989\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7996 - accuracy: 0.6403 - val_loss: 0.8686 - val_accuracy: 0.5829\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8131 - accuracy: 0.6266 - val_loss: 0.8597 - val_accuracy: 0.5882\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.6284 - val_loss: 0.8569 - val_accuracy: 0.5882\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8004 - accuracy: 0.6373 - val_loss: 0.8632 - val_accuracy: 0.5989\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8129 - accuracy: 0.6361 - val_loss: 0.8646 - val_accuracy: 0.5829\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.6284 - val_loss: 0.8516 - val_accuracy: 0.6096\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8053 - accuracy: 0.6326 - val_loss: 0.8588 - val_accuracy: 0.5936\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7933 - accuracy: 0.6391 - val_loss: 0.8628 - val_accuracy: 0.5936\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8059 - accuracy: 0.6278 - val_loss: 0.8521 - val_accuracy: 0.6043\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8017 - accuracy: 0.6474 - val_loss: 0.8551 - val_accuracy: 0.5989\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8002 - accuracy: 0.6421 - val_loss: 0.8610 - val_accuracy: 0.5936\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7980 - accuracy: 0.6391 - val_loss: 0.8633 - val_accuracy: 0.5829\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8026 - accuracy: 0.6326 - val_loss: 0.8606 - val_accuracy: 0.5989\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7931 - accuracy: 0.6367 - val_loss: 0.8506 - val_accuracy: 0.5936\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7853 - accuracy: 0.6457 - val_loss: 0.8508 - val_accuracy: 0.6043\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7983 - accuracy: 0.6290 - val_loss: 0.8555 - val_accuracy: 0.6043\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7885 - accuracy: 0.6528 - val_loss: 0.8567 - val_accuracy: 0.6096\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8020 - accuracy: 0.6361 - val_loss: 0.8503 - val_accuracy: 0.6096\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7990 - accuracy: 0.6385 - val_loss: 0.8611 - val_accuracy: 0.5722\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7871 - accuracy: 0.6457 - val_loss: 0.8638 - val_accuracy: 0.5989\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7961 - accuracy: 0.6314 - val_loss: 0.8600 - val_accuracy: 0.5882\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7980 - accuracy: 0.6249 - val_loss: 0.8557 - val_accuracy: 0.6043\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7848 - accuracy: 0.6474 - val_loss: 0.8580 - val_accuracy: 0.6043\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7926 - accuracy: 0.6421 - val_loss: 0.8555 - val_accuracy: 0.5936\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.6373 - val_loss: 0.8514 - val_accuracy: 0.6096\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8025 - accuracy: 0.6451 - val_loss: 0.8540 - val_accuracy: 0.6043\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7775 - accuracy: 0.6457 - val_loss: 0.8494 - val_accuracy: 0.5989\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7885 - accuracy: 0.6445 - val_loss: 0.8527 - val_accuracy: 0.6203\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7879 - accuracy: 0.6361 - val_loss: 0.8533 - val_accuracy: 0.5989\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.6415 - val_loss: 0.8499 - val_accuracy: 0.6043\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7788 - accuracy: 0.6409 - val_loss: 0.8541 - val_accuracy: 0.6043\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7868 - accuracy: 0.6451 - val_loss: 0.8539 - val_accuracy: 0.5989\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.6379 - val_loss: 0.8596 - val_accuracy: 0.5989\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.6385 - val_loss: 0.8521 - val_accuracy: 0.5936\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7855 - accuracy: 0.6344 - val_loss: 0.8551 - val_accuracy: 0.5936\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.6361 - val_loss: 0.8691 - val_accuracy: 0.5989\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7799 - accuracy: 0.6415 - val_loss: 0.8575 - val_accuracy: 0.5882\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7793 - accuracy: 0.6373 - val_loss: 0.8543 - val_accuracy: 0.5882\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7631 - accuracy: 0.6653 - val_loss: 0.8611 - val_accuracy: 0.5829\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8040 - accuracy: 0.6427 - val_loss: 0.8600 - val_accuracy: 0.5936\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.6570 - val_loss: 0.8587 - val_accuracy: 0.5989\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7816 - accuracy: 0.6534 - val_loss: 0.8572 - val_accuracy: 0.5829\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 0.6385 - val_loss: 0.8594 - val_accuracy: 0.5882\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.6486 - val_loss: 0.8563 - val_accuracy: 0.5936\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7676 - accuracy: 0.6593 - val_loss: 0.8574 - val_accuracy: 0.5882\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7707 - accuracy: 0.6510 - val_loss: 0.8544 - val_accuracy: 0.6043\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7808 - accuracy: 0.6427 - val_loss: 0.8675 - val_accuracy: 0.5882\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7682 - accuracy: 0.6528 - val_loss: 0.8645 - val_accuracy: 0.5829\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.6546 - val_loss: 0.8634 - val_accuracy: 0.6096\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.6611 - val_loss: 0.8573 - val_accuracy: 0.5882\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7749 - accuracy: 0.6498 - val_loss: 0.8518 - val_accuracy: 0.6043\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.6558 - val_loss: 0.8531 - val_accuracy: 0.5882\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7700 - accuracy: 0.6576 - val_loss: 0.8554 - val_accuracy: 0.5989\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7763 - accuracy: 0.6427 - val_loss: 0.8455 - val_accuracy: 0.6043\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7625 - accuracy: 0.6576 - val_loss: 0.8562 - val_accuracy: 0.6043\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7646 - accuracy: 0.6522 - val_loss: 0.8527 - val_accuracy: 0.5882\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.6623 - val_loss: 0.8571 - val_accuracy: 0.5936\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7686 - accuracy: 0.6546 - val_loss: 0.8599 - val_accuracy: 0.5936\n",
      "7/7 [==============================] - 0s 637us/step - loss: 0.8887 - accuracy: 0.6202\n",
      "Test Accuracy: 0.620192289352417\n"
     ]
    }
   ],
   "source": [
    "for trait in traits:\n",
    "    print(f\"Processing {trait}\")\n",
    "    trait_bin = trait + \"_bin\"\n",
    "    label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    y_train = np.array([label_mapping[label] for label in y_train_org[trait_bin]])\n",
    "    y_test = np.array([label_mapping[label] for label in y_test_org[trait_bin]])\n",
    "\n",
    "    num_classes = len(np.unique(y_test)) \n",
    "\n",
    "    # Define the CNN model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dropout(0.5),  # Add dropout to reduce overfitting\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')  # Adjust the output layer units based on your problem\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',  # Use this loss for multiclass classification\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Display the model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 64\n",
    "    epochs = 200\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    break\n",
    "    # Save the trained model to a file\n",
    "    # model.save(\"ecg_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascertain-investigation-iYp4vF4l-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
